# Arquitectura del Proyecto - Sistema IoT-IDS

## DescripciÃ³n General

Este documento describe la arquitectura completa de la aplicaciÃ³n de demostraciÃ³n del Sistema de DetecciÃ³n de Intrusiones IoT, incluyendo la estructura de archivos, componentes, flujos de datos y dependencias.

---

## Estructura de Directorios

```
Dashboard IoT-IDS/
â”‚
â”œâ”€â”€ app.py                              # AplicaciÃ³n principal Streamlit
â”‚
â”œâ”€â”€ pages/                              # PÃ¡ginas multi-pÃ¡gina de Streamlit
â”‚   â”œâ”€â”€ 1_ðŸ”¬_Comparacion_Modelos.py    # ComparaciÃ³n lado a lado
â”‚   â”œâ”€â”€ 2_âš¡_Tiempo_Real.py            # SimulaciÃ³n en tiempo real
â”‚   â”œâ”€â”€ 3_ðŸ“Š_Analisis_Archivo.py       # AnÃ¡lisis batch de CSV
â”‚   â””â”€â”€ 4_ðŸ“ˆ_Metricas.py               # Dashboard de mÃ©tricas
â”‚
â”œâ”€â”€ utils/                              # MÃ³dulos de utilidades
â”‚   â”œâ”€â”€ __init__.py                     # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ model_loader.py                 # Carga y gestiÃ³n de modelos
â”‚   â”œâ”€â”€ data_simulator.py               # GeneraciÃ³n de datos sintÃ©ticos
â”‚   â”œâ”€â”€ visualizations.py               # GrÃ¡ficos y visualizaciones
â”‚   â””â”€â”€ report_generator.py             # GeneraciÃ³n de reportes PDF
â”‚
â”œâ”€â”€ models/                             # Modelos entrenados
â”‚   â”œâ”€â”€ modelo_ae_fnn_iot_synthetic.h5
â”‚   â”œâ”€â”€ modelo_ae_fnn_iot_real.h5
â”‚   â”œâ”€â”€ scaler_synthetic.pkl
â”‚   â”œâ”€â”€ scaler_real.pkl
â”‚   â”œâ”€â”€ label_encoder_synthetic.pkl
â”‚   â”œâ”€â”€ label_encoder_real.pkl
â”‚   â”œâ”€â”€ class_names_synthetic.npy
â”‚   â”œâ”€â”€ class_names_real.npy
â”‚   â”œâ”€â”€ model_metadata_synthetic.json
â”‚   â””â”€â”€ model_metadata_real.json
â”‚
â”œâ”€â”€ data/                               # Datasets de ejemplo
â”‚   â”œâ”€â”€ dataset_pca_capa3_iot_ultra_fixed_100k_dataset.csv
â”‚   â”œâ”€â”€ CICIoT2023_samples.csv
â”‚   â””â”€â”€ ejemplos/                       # Archivos de ejemplo para pruebas
â”‚       â”œâ”€â”€ sample_normal.csv
â”‚       â”œâ”€â”€ sample_ddos.csv
â”‚       â””â”€â”€ sample_mixed.csv
â”‚
â”œâ”€â”€ docs/                               # DocumentaciÃ³n
â”‚   â”œâ”€â”€ IMPLEMENTACION.md               # GuÃ­a de implementaciÃ³n
â”‚   â”œâ”€â”€ MODELOS.md                      # DocumentaciÃ³n tÃ©cnica de modelos
â”‚   â”œâ”€â”€ ARQUITECTURA.md                 # Este archivo
â”‚   â”œâ”€â”€ OBJETIVOS_TESIS.md              # AlineaciÃ³n con objetivos
â”‚   â””â”€â”€ assets/                         # Recursos para documentaciÃ³n
â”‚       â”œâ”€â”€ diagrams/
â”‚       â””â”€â”€ screenshots/
â”‚
â”œâ”€â”€ tests/                              # Tests unitarios (opcional)
â”‚   â”œâ”€â”€ test_model_loader.py
â”‚   â”œâ”€â”€ test_data_simulator.py
â”‚   â””â”€â”€ test_predictions.py
â”‚
â”œâ”€â”€ .streamlit/                         # ConfiguraciÃ³n de Streamlit
â”‚   â””â”€â”€ config.toml                     # Tema y configuraciones
â”‚
â”œâ”€â”€ requirements.txt                    # Dependencias de Python
â”œâ”€â”€ .gitignore                          # Archivos ignorados por git
â”œâ”€â”€ README.md                           # DocumentaciÃ³n principal
â””â”€â”€ LICENSE                             # Licencia del proyecto
```

---

## Componentes Principales

### 1. AplicaciÃ³n Principal (`app.py`)

**Responsabilidades:**
- ConfiguraciÃ³n global de Streamlit
- PÃ¡gina de inicio/home
- SelecciÃ³n de modelo (SintÃ©tico vs Real)
- Carga inicial de modelos
- NavegaciÃ³n entre pÃ¡ginas

**Funciones principales:**
```python
def main():
    """FunciÃ³n principal de la aplicaciÃ³n"""
    - Configurar pÃ¡gina (tÃ­tulo, icono, layout)
    - Renderizar sidebar con selector de modelo
    - Cargar modelo seleccionado en session_state
    - Mostrar mÃ©tricas generales
    - Instrucciones de uso

def load_selected_model(model_choice):
    """Carga el modelo seleccionado por el usuario"""
    - Verificar si el modelo ya estÃ¡ en cache
    - Cargar componentes (modelo, scaler, encoder)
    - Guardar en st.session_state
    - Retornar Ã©xito/error
```

**Estado de sesiÃ³n gestionado:**
```python
st.session_state = {
    'current_model': 'synthetic' | 'real',
    'model': <Keras Model>,
    'scaler': <StandardScaler>,
    'label_encoder': <LabelEncoder>,
    'class_names': <np.array>,
    'metadata': <dict>
}
```

---

### 2. PÃ¡ginas Streamlit

#### 2.1 ComparaciÃ³n de Modelos (`1_ðŸ”¬_Comparacion_Modelos.py`)

**Funcionalidades:**
- ComparaciÃ³n lado a lado de predicciones
- GeneraciÃ³n de muestras aleatorias
- AnÃ¡lisis batch de archivos CSV
- VisualizaciÃ³n comparativa

**Componentes UI:**
- Columnas izquierda/derecha para cada modelo
- BotÃ³n "Generar Muestra Aleatoria"
- File uploader para CSV
- GrÃ¡ficos de barras comparativos
- Tabla de resultados

**Estado local:**
```python
st.session_state = {
    'comparison_results': pd.DataFrame,
    'last_sample': np.array,
    'concordance_rate': float
}
```

#### 2.2 Tiempo Real (`2_âš¡_Tiempo_Real.py`)

**Funcionalidades:**
- SimulaciÃ³n de trÃ¡fico IoT continuo
- Monitoreo en tiempo real
- Alertas visuales por nivel de riesgo
- SimulaciÃ³n de escenarios especÃ­ficos

**Componentes UI:**
- Botones Start/Pause/Reset
- MÃ©tricas en vivo (total muestras, amenazas, riesgo)
- GrÃ¡fico temporal scrollable
- Log de detecciones
- Botones de simulaciÃ³n de ataques

**Estado local:**
```python
st.session_state = {
    'simulation_running': bool,
    'threat_history': deque(maxlen=60),
    'threat_counts': dict,
    'total_samples': int,
    'last_detection': dict
}
```

**Loop de simulaciÃ³n:**
```python
while st.session_state.simulation_running:
    - Generar muestra simulada
    - Predecir con modelo
    - Actualizar contadores
    - Actualizar visualizaciones
    - Mostrar alerta si es amenaza
    - sleep(1)  # 1 muestra/segundo
```

#### 2.3 AnÃ¡lisis de Archivo (`3_ðŸ“Š_Analisis_Archivo.py`)

**Funcionalidades:**
- Upload de archivos CSV
- ValidaciÃ³n de formato
- Procesamiento batch
- GeneraciÃ³n de reportes
- ExportaciÃ³n de resultados

**Componentes UI:**
- File uploader
- Preview de datos
- Barra de progreso
- Tabla de resultados
- Visualizaciones (distribuciÃ³n, matriz confusiÃ³n)
- Botones de descarga (CSV, PDF)

**Flujo de procesamiento:**
```
1. Usuario sube archivo CSV
2. Validar formato (16 columnas + opcional label)
3. Mostrar preview
4. Usuario selecciona modelo y presiona "Analizar"
5. Iterar sobre muestras con barra de progreso
6. Generar predicciones
7. Calcular mÃ©tricas (si hay labels)
8. Visualizar resultados
9. Permitir descarga de reporte
```

#### 2.4 MÃ©tricas (`4_ðŸ“ˆ_Metricas.py`)

**Funcionalidades:**
- VisualizaciÃ³n de mÃ©tricas de ambos modelos
- InformaciÃ³n tÃ©cnica de arquitectura
- JustificaciÃ³n acadÃ©mica
- Cumplimiento de objetivos de tesis

**Componentes UI:**
- Tabs (SintÃ©tico, Real, TÃ©cnico)
- Tarjetas de mÃ©tricas
- GrÃ¡ficos de rendimiento
- Tablas comparativas
- SecciÃ³n de justificaciÃ³n acadÃ©mica

---

### 3. MÃ³dulos de Utilidades

#### 3.1 `utils/model_loader.py`

**PropÃ³sito:** Gestionar carga de modelos y predicciones

**Funciones principales:**

```python
@st.cache_resource
def load_synthetic_model():
    """
    Carga el modelo sintÃ©tico y todos sus componentes

    Returns:
        model, scaler, label_encoder, class_names, metadata
    """

@st.cache_resource
def load_real_model():
    """
    Carga el modelo real y todos sus componentes

    Returns:
        model, scaler, label_encoder, class_names, metadata
    """

def predict_sample(model, scaler, label_encoder, class_names, sample):
    """
    Predice la clase de una muestra

    Args:
        model: Modelo Keras
        scaler: StandardScaler
        label_encoder: LabelEncoder
        class_names: Array de nombres de clases
        sample: Array de 16 features

    Returns:
        prediction: Clase predicha (str)
        probabilities: Array de probabilidades
        confidence: Confianza en % (float)
    """

def predict_batch(model, scaler, label_encoder, class_names, X_batch):
    """
    Predice mÃºltiples muestras en batch

    Args:
        X_batch: Array (n_samples, 16)

    Returns:
        predictions: Lista de predicciones
        confidences: Lista de confianzas
    """

def verify_model_compatibility(model):
    """
    Verifica que el modelo tenga la estructura esperada

    Returns:
        bool: True si es compatible
        str: Mensaje de error si no es compatible
    """
```

**Manejo de cache:**
```python
# Usa @st.cache_resource para cargar modelos una sola vez
# Persiste en memoria durante toda la sesiÃ³n
# Comparte entre usuarios (multitenancy)
```

#### 3.2 `utils/data_simulator.py`

**PropÃ³sito:** Generar datos sintÃ©ticos para simulaciÃ³n

**Funciones principales:**

```python
def generate_traffic_sample(attack_type=None):
    """
    Genera una muestra de trÃ¡fico IoT

    Args:
        attack_type: 'DDoS', 'DoS', etc. o None (aleatorio)

    Returns:
        sample: Array de 16 componentes PCA
        label: Etiqueta verdadera
    """

def generate_attack_pattern(attack_type):
    """
    Genera patrÃ³n caracterÃ­stico de un ataque

    Args:
        attack_type: Tipo de ataque

    Returns:
        sample: Array de 16 componentes con patrÃ³n del ataque
    """

def generate_attack_burst(attack_type, count=10):
    """
    Genera rÃ¡faga de muestras del mismo ataque

    Args:
        attack_type: Tipo de ataque
        count: NÃºmero de muestras

    Returns:
        samples: Lista de (sample, label)
    """

def generate_mixed_traffic(duration_seconds=60):
    """
    Genera trÃ¡fico mixto para simulaciÃ³n temporal

    Args:
        duration_seconds: DuraciÃ³n de la simulaciÃ³n

    Returns:
        timeline: Lista de (timestamp, sample, label)
    """
```

**Patrones de ataque implementados:**
```python
ATTACK_PATTERNS = {
    'DDoS': {
        'pc1_multiplier': 3.0,
        'pc2_multiplier': 2.5,
        'pc3_multiplier': 2.0,
        'noise_level': 0.2
    },
    'Brute_Force': {
        'pc5_multiplier': 4.0,
        'pc6_multiplier': 3.0,
        'repetitive': True
    },
    # ... otros patrones
}
```

#### 3.3 `utils/visualizations.py`

**PropÃ³sito:** Funciones de visualizaciÃ³n reutilizables

**Funciones principales:**

```python
def plot_confusion_matrix(y_true, y_pred, class_names):
    """
    Genera matriz de confusiÃ³n con seaborn

    Returns:
        fig: Figura de matplotlib
    """

def plot_temporal_chart(threat_history):
    """
    GrÃ¡fico temporal de detecciones

    Args:
        threat_history: deque con histÃ³rico

    Returns:
        fig: Figura de Plotly
    """

def plot_class_distribution(predictions):
    """
    GrÃ¡fico de pastel con distribuciÃ³n de clases

    Returns:
        fig: Figura de Plotly
    """

def plot_confidence_comparison(results_df):
    """
    GrÃ¡fico de barras comparando confianzas

    Returns:
        fig: Figura de Plotly
    """

def plot_metrics_radar(metrics_dict):
    """
    GrÃ¡fico radar con mÃºltiples mÃ©tricas

    Returns:
        fig: Figura de Plotly
    """

def create_risk_gauge(risk_level):
    """
    VelocÃ­metro de nivel de riesgo

    Args:
        risk_level: 0-100

    Returns:
        fig: Figura de Plotly
    """
```

#### 3.4 `utils/report_generator.py`

**PropÃ³sito:** Generar reportes PDF

**Funciones principales:**

```python
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Table

def generate_pdf_report(results_df, model_name, metadata):
    """
    Genera reporte PDF completo

    Args:
        results_df: DataFrame con resultados
        model_name: Nombre del modelo usado
        metadata: Metadatos adicionales

    Returns:
        bytes: Contenido del PDF
    """

def add_header(pdf, title):
    """Agrega encabezado al PDF"""

def add_metrics_section(pdf, metrics):
    """Agrega secciÃ³n de mÃ©tricas"""

def add_visualizations(pdf, figures):
    """Agrega grÃ¡ficos al PDF"""

def add_footer(pdf, timestamp):
    """Agrega pie de pÃ¡gina con timestamp"""
```

---

## Flujos de Datos

### Flujo 1: Carga de Modelo

```
Usuario â†’ Selecciona modelo en sidebar
    â†“
app.py â†’ load_selected_model(choice)
    â†“
utils/model_loader.py â†’ load_synthetic_model() o load_real_model()
    â†“
    â”œâ”€â†’ Cargar modelo.h5 (TensorFlow)
    â”œâ”€â†’ Cargar scaler.pkl (pickle)
    â”œâ”€â†’ Cargar label_encoder.pkl (pickle)
    â”œâ”€â†’ Cargar class_names.npy (numpy)
    â””â”€â†’ Cargar metadata.json (json)
    â†“
Almacenar en st.session_state
    â†“
Modelo disponible para todas las pÃ¡ginas
```

### Flujo 2: PredicciÃ³n de Muestra Ãšnica

```
Usuario â†’ Genera muestra aleatoria o sube datos
    â†“
PÃ¡gina Streamlit â†’ Obtener muestra (16 features)
    â†“
utils/model_loader.py â†’ predict_sample(model, scaler, encoder, sample)
    â†“
    1. Normalizar muestra con scaler.transform()
    2. Predecir con model.predict()
    3. Extraer salida de clasificaciÃ³n (output[1])
    4. Obtener clase con argmax
    5. Decodificar con label_encoder.inverse_transform()
    6. Calcular confianza (max probability)
    â†“
Retornar â†’ (prediction, probabilities, confidence)
    â†“
PÃ¡gina Streamlit â†’ Mostrar resultados
```

### Flujo 3: SimulaciÃ³n en Tiempo Real

```
Usuario â†’ Presiona "Iniciar SimulaciÃ³n"
    â†“
st.session_state.simulation_running = True
    â†“
Loop continuo (cada 1 segundo):
    â”œâ”€â†’ utils/data_simulator.py â†’ generate_traffic_sample()
    â”‚       â””â”€â†’ Retorna (sample, true_label)
    â”œâ”€â†’ utils/model_loader.py â†’ predict_sample(sample)
    â”‚       â””â”€â†’ Retorna (prediction, probs, confidence)
    â”œâ”€â†’ Actualizar threat_history (agregar nueva detecciÃ³n)
    â”œâ”€â†’ Actualizar threat_counts (incrementar contador)
    â”œâ”€â†’ Actualizar visualizaciones (grÃ¡fico temporal)
    â”œâ”€â†’ Mostrar alerta si es amenaza
    â””â”€â†’ sleep(1)
    â†“
Usuario â†’ Presiona "Pausar"
    â†“
st.session_state.simulation_running = False
```

### Flujo 4: AnÃ¡lisis de Archivo

```
Usuario â†’ Sube archivo CSV
    â†“
Streamlit â†’ file_uploader() retorna UploadedFile
    â†“
pd.read_csv() â†’ DataFrame
    â†“
Validar formato:
    â”œâ”€â†’ Verificar 16 columnas de features
    â”œâ”€â†’ Detectar columna 'label' opcional
    â””â”€â†’ Verificar tipos de datos
    â†“
Usuario â†’ Presiona "Analizar"
    â†“
For each row in DataFrame:
    â”œâ”€â†’ Extraer sample (16 features)
    â”œâ”€â†’ predict_sample(sample)
    â”œâ”€â†’ Almacenar resultado
    â””â”€â†’ Actualizar progress bar
    â†“
Si hay labels:
    â”œâ”€â†’ Calcular accuracy, precision, recall, f1
    â””â”€â†’ Generar matriz de confusiÃ³n
    â†“
Visualizar resultados:
    â”œâ”€â†’ Tabla de predicciones
    â”œâ”€â†’ DistribuciÃ³n de clases
    â”œâ”€â†’ Top amenazas
    â””â”€â†’ Matriz de confusiÃ³n
    â†“
Usuario â†’ Descarga reporte (CSV o PDF)
    â†“
utils/report_generator.py â†’ generate_pdf_report()
    â†“
Retornar bytes del PDF
```

---

## GestiÃ³n de Estado

### Session State en Streamlit

Streamlit es stateless por defecto. Usamos `st.session_state` para persistencia.

**Variables globales (app.py):**
```python
st.session_state = {
    # Modelo seleccionado
    'current_model': 'synthetic' | 'real',

    # Componentes del modelo cargado
    'model': <Keras Model>,
    'scaler': <StandardScaler>,
    'label_encoder': <LabelEncoder>,
    'class_names': np.array,
    'metadata': dict,

    # Flags de estado
    'model_loaded': bool,
    'first_run': bool
}
```

**Variables especÃ­ficas de pÃ¡gina (2_âš¡_Tiempo_Real.py):**
```python
st.session_state = {
    'simulation_running': False,
    'threat_history': deque(maxlen=60),
    'threat_counts': {
        'Benign': 0, 'DDoS': 0, ...
    },
    'total_samples': 0,
    'start_time': timestamp
}
```

**Variables especÃ­ficas de pÃ¡gina (3_ðŸ“Š_Analisis_Archivo.py):**
```python
st.session_state = {
    'analysis_results': pd.DataFrame,
    'uploaded_file_hash': str,
    'has_labels': bool,
    'metrics': dict
}
```

### Cache de Streamlit

**@st.cache_resource:**
- Cachea modelos ML (persistencia en memoria)
- Comparte entre sesiones de usuarios
- No se serializa, almacena el objeto directamente

```python
@st.cache_resource
def load_synthetic_model():
    # Se ejecuta solo una vez
    # Resultado se comparte entre todos los usuarios
    pass
```

**@st.cache_data:**
- Cachea DataFrames y datos computados
- Serializa y deserializa automÃ¡ticamente
- Ideal para procesamiento de datos

```python
@st.cache_data
def load_dataset(file_path):
    # Se ejecuta solo si file_path cambia
    return pd.read_csv(file_path)
```

---

## Dependencias del Proyecto

### requirements.txt

```txt
# Core
python>=3.8

# Machine Learning
tensorflow>=2.10.0
keras>=2.10.0
scikit-learn>=1.2.0
numpy>=1.23.0

# Data Processing
pandas>=1.5.0

# Visualization
plotly>=5.14.0
matplotlib>=3.6.0
seaborn>=0.12.0

# Web Framework
streamlit>=1.25.0

# Report Generation
reportlab>=3.6.0
Pillow>=9.5.0

# Utilities
python-dateutil>=2.8.0
```

### Diagrama de Dependencias

```
app.py
    â”œâ”€â”€ streamlit
    â”œâ”€â”€ utils.model_loader
    â”‚       â”œâ”€â”€ tensorflow
    â”‚       â”œâ”€â”€ scikit-learn
    â”‚       â””â”€â”€ numpy
    â””â”€â”€ pages/
            â”œâ”€â”€ 1_Comparacion_Modelos.py
            â”‚       â”œâ”€â”€ utils.model_loader
            â”‚       â”œâ”€â”€ utils.visualizations
            â”‚       â””â”€â”€ plotly
            â”œâ”€â”€ 2_Tiempo_Real.py
            â”‚       â”œâ”€â”€ utils.model_loader
            â”‚       â”œâ”€â”€ utils.data_simulator
            â”‚       â”œâ”€â”€ utils.visualizations
            â”‚       â””â”€â”€ plotly
            â”œâ”€â”€ 3_Analisis_Archivo.py
            â”‚       â”œâ”€â”€ utils.model_loader
            â”‚       â”œâ”€â”€ utils.visualizations
            â”‚       â”œâ”€â”€ utils.report_generator
            â”‚       â”œâ”€â”€ pandas
            â”‚       â””â”€â”€ plotly
            â””â”€â”€ 4_Metricas.py
                    â”œâ”€â”€ utils.visualizations
                    â””â”€â”€ plotly
```

---

## ConfiguraciÃ³n de Streamlit

### `.streamlit/config.toml`

```toml
[theme]
primaryColor = "#FF4B4B"
backgroundColor = "#0E1117"
secondaryBackgroundColor = "#262730"
textColor = "#FAFAFA"
font = "sans serif"

[server]
port = 8501
enableCORS = false
enableXsrfProtection = true

[browser]
gatherUsageStats = false

[runner]
magicEnabled = true
fastReruns = true
```

---

## Consideraciones de Seguridad

### 1. ValidaciÃ³n de Entrada

- **Archivos CSV**: Validar formato, tamaÃ±o mÃ¡ximo, tipos de datos
- **Muestras simuladas**: Limitar rangos de valores
- **Paths**: Evitar path traversal attacks

### 2. Manejo de Modelos

- **VerificaciÃ³n**: Checksum de archivos .h5 antes de cargar
- **Sandboxing**: Ejecutar predicciones en modo restringido
- **Timeout**: LÃ­mite de tiempo para inferencia

### 3. GestiÃ³n de Sesiones

- **LÃ­mite de datos**: Limpiar session_state periÃ³dicamente
- **Timeout de sesiÃ³n**: Invalidar sesiones inactivas
- **Aislamiento**: Cada usuario tiene session_state separado

---

## Escalabilidad

### Limitaciones Actuales

- **Concurrencia**: Streamlit single-threaded por sesiÃ³n
- **Memoria**: Modelos cargados en RAM (~150KB c/u)
- **SimulaciÃ³n**: Loop sÃ­ncrono, bloquea UI

### Mejoras Futuras

1. **Async Processing**: Usar asyncio para simulaciÃ³n
2. **Background Workers**: Celery para procesamiento batch
3. **Database**: Persistir resultados en DB (PostgreSQL, MongoDB)
4. **Queue System**: RabbitMQ para manejar mÃºltiples anÃ¡lisis
5. **ContainerizaciÃ³n**: Docker para despliegue consistente

---

## Deployment

### Opciones de Despliegue

#### 1. Streamlit Cloud (Recomendado para demo)
```bash
# Push a GitHub
git push origin main

# Conectar en streamlit.io
# Auto-deploy desde repositorio
```

#### 2. Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501"]
```

#### 3. Cloud Platforms
- **Google Cloud Run**: Serverless, auto-scaling
- **AWS EC2**: VM tradicional
- **Heroku**: PaaS simplificado

---

## Monitoreo y Logging

### Logs de AplicaciÃ³n

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Uso
logger.info("Modelo cargado exitosamente")
logger.warning("Confianza baja en predicciÃ³n")
logger.error("Error al cargar archivo CSV")
```

### MÃ©tricas de Uso

```python
# Trackear en session_state
st.session_state.metrics = {
    'total_predictions': 0,
    'total_files_analyzed': 0,
    'simulation_time': 0,
    'avg_inference_time': 0.0
}
```

---

## Testing

### Estructura de Tests

```python
# tests/test_model_loader.py
import pytest
from utils.model_loader import load_synthetic_model, predict_sample

def test_load_synthetic_model():
    model, scaler, encoder, names, meta = load_synthetic_model()
    assert model is not None
    assert scaler is not None

def test_predict_sample():
    sample = np.random.randn(16)
    pred, probs, conf = predict_sample(model, scaler, encoder, names, sample)
    assert isinstance(pred, str)
    assert 0 <= conf <= 100
```

### Comandos de Testing

```bash
# Ejecutar todos los tests
pytest tests/

# Con cobertura
pytest --cov=utils tests/

# Test especÃ­fico
pytest tests/test_model_loader.py::test_predict_sample
```

---

**Ãšltima actualizaciÃ³n**: Noviembre 2024
