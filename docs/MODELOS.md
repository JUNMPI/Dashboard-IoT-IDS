# Documentaci√≥n T√©cnica de Modelos

## Descripci√≥n General

Este documento detalla las especificaciones t√©cnicas de los dos modelos Autoencoder-FNN (AE-FNN) desarrollados para la detecci√≥n de amenazas en redes IoT.

---

## Arquitectura: Autoencoder-FNN Multi-tarea

### Concepto

El modelo combina dos arquitecturas de deep learning en un enfoque multi-tarea:

1. **Autoencoder (AE)**: Aprende representaciones compactas de los datos
2. **Feedforward Neural Network (FNN)**: Clasifica las amenazas

### Ventajas del Enfoque Multi-tarea

- **Mejor generalizaci√≥n**: El autoencoder obliga al modelo a aprender features relevantes
- **Reducci√≥n de overfitting**: La tarea de reconstrucci√≥n act√∫a como regularizador
- **Detecci√≥n de anomal√≠as**: El error de reconstrucci√≥n puede identificar patrones desconocidos
- **Efficiency**: Comparte representaciones entre tareas

---

## Arquitectura Detallada

### 1. Encoder (Compresi√≥n)

```
Input Layer:  16 features (PC1 - PC16)
     ‚Üì
Dense Layer:  8 neurons
     - Activation: ReLU
     - Kernel Initializer: he_normal
     ‚Üì
Latent Space: 4 neurons (bottleneck)
     - Activation: ReLU
     - Kernel Initializer: he_normal
```

**Prop√≥sito**: Comprimir informaci√≥n de 16 dimensiones a 4 dimensiones, extrayendo caracter√≠sticas esenciales.

### 2. Decoder (Reconstrucci√≥n)

```
Latent Space: 4 neurons
     ‚Üì
Dense Layer:  8 neurons
     - Activation: ReLU
     - Kernel Initializer: he_normal
     ‚Üì
Output Layer: 16 neurons (reconstrucci√≥n)
     - Activation: Linear
```

**Prop√≥sito**: Reconstruir la entrada original a partir de la representaci√≥n comprimida.

### 3. Clasificador (Clasificaci√≥n Multi-clase)

```
Latent Space: 4 neurons (compartido con Encoder)
     ‚Üì
Dense Layer:  16 neurons
     - Activation: ReLU
     - Dropout: 0.3
     - Kernel Initializer: he_normal
     ‚Üì
Output Layer: 8 neurons (clases)
     - Activation: Softmax
```

**Prop√≥sito**: Clasificar el tr√°fico en 8 categor√≠as (7 tipos de ataques + tr√°fico normal).

---

## Clases de Salida

El modelo clasifica el tr√°fico en las siguientes 8 clases:

| Clase | Descripci√≥n | Tipo |
|-------|-------------|------|
| `Benign` | Tr√°fico normal, leg√≠timo | Normal |
| `DDoS` | Distributed Denial of Service | Ataque |
| `DoS` | Denial of Service | Ataque |
| `Brute_Force` | Intentos de acceso por fuerza bruta | Ataque |
| `Spoofing` | Suplantaci√≥n de identidad | Ataque |
| `MITM` | Man-in-the-Middle | Ataque |
| `Scan` | Escaneo de puertos/servicios | Ataque |
| `Recon` | Reconocimiento de red | Ataque |

---

## Funci√≥n de P√©rdida Combinada

### F√≥rmula

```
Total Loss = Œª‚ÇÅ √ó Loss_reconstruction + Œª‚ÇÇ √ó Loss_classification

donde:
- Loss_reconstruction = MSE (Mean Squared Error)
- Loss_classification = Categorical Cross-Entropy
- Œª‚ÇÅ, Œª‚ÇÇ = pesos de cada tarea
```

### Hiperpar√°metros de P√©rdida

**Modelo Sint√©tico:**
- Œª‚ÇÅ (reconstrucci√≥n) = 0.3
- Œª‚ÇÇ (clasificaci√≥n) = 0.7

**Modelo Real:**
- Œª‚ÇÅ (reconstrucci√≥n) = 0.3
- Œª‚ÇÇ (clasificaci√≥n) = 0.7

**Justificaci√≥n**: Se prioriza la clasificaci√≥n (0.7) sobre la reconstrucci√≥n (0.3) dado que el objetivo principal es detectar amenazas, no comprimir datos.

---

## Modelo 1: Sint√©tico

### Caracter√≠sticas

| Par√°metro | Valor |
|-----------|-------|
| **Dataset** | Sint√©tico PCA (100,000 muestras) |
| **Features de Entrada** | 16 componentes PCA |
| **Accuracy** | 97.00% |
| **Precision (weighted)** | 96.85% |
| **Recall (weighted)** | 96.72% |
| **F1-Score (weighted)** | 96.78% |
| **False Positive Rate** | <2% |

### Archivos del Modelo

```
models/
‚îú‚îÄ‚îÄ modelo_ae_fnn_iot_synthetic.h5        # Modelo entrenado (Keras)
‚îú‚îÄ‚îÄ scaler_synthetic.pkl                   # StandardScaler (scikit-learn)
‚îú‚îÄ‚îÄ label_encoder_synthetic.pkl            # LabelEncoder (scikit-learn)
‚îú‚îÄ‚îÄ class_names_synthetic.npy              # Array con nombres de clases
‚îî‚îÄ‚îÄ model_metadata_synthetic.json          # Metadatos (arquitectura, m√©tricas)
```

### Dataset de Entrenamiento

- **Tama√±o**: 100,000 muestras
- **Distribuci√≥n**: Balanceada (~12,500 muestras por clase)
- **Features**: 16 componentes PCA (reducci√≥n de 35 features originales)
- **Preprocesamiento**:
  - Normalizaci√≥n con StandardScaler
  - Reducci√≥n dimensional PCA
  - Balanceo de clases

### M√©tricas por Clase

| Clase | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Benign | 0.98 | 0.98 | 0.98 | 2500 |
| DDoS | 0.97 | 0.97 | 0.97 | 2500 |
| DoS | 0.96 | 0.96 | 0.96 | 2500 |
| Brute_Force | 0.96 | 0.95 | 0.95 | 2500 |
| Spoofing | 0.97 | 0.97 | 0.97 | 2500 |
| **MITM** | 0.95 | **0.68** | **0.89** | 2500 |
| Scan | 0.97 | 0.96 | 0.96 | 2500 |
| Recon | 0.96 | 0.95 | 0.95 | 2500 |

**Nota**: MITM presenta el menor recall (68%) debido a similitudes con tr√°fico normal en algunas caracter√≠sticas.

### Rendimiento Temporal

- **Tiempo de Inferencia**: <2ms por muestra
- **Throughput**: ~500 muestras/segundo
- **Tama√±o del Modelo**: ~150 KB

---

## Modelo 2: Real (CICIoT2023)

### Caracter√≠sticas

| Par√°metro | Valor |
|-----------|-------|
| **Dataset** | CICIoT2023 (datos reales) |
| **Features de Entrada** | 16 componentes PCA |
| **Accuracy** | 84.48% |
| **Precision (weighted)** | 83.20% |
| **Recall (weighted)** | 82.95% |
| **F1-Score (weighted)** | 83.07% |
| **False Positive Rate** | ~3-4% |

### Archivos del Modelo

```
models/
‚îú‚îÄ‚îÄ modelo_ae_fnn_iot_real.h5             # Modelo entrenado (Keras)
‚îú‚îÄ‚îÄ scaler_real.pkl                        # StandardScaler (scikit-learn)
‚îú‚îÄ‚îÄ label_encoder_real.pkl                 # LabelEncoder (scikit-learn)
‚îú‚îÄ‚îÄ class_names_real.npy                   # Array con nombres de clases
‚îî‚îÄ‚îÄ model_metadata_real.json               # Metadatos (arquitectura, m√©tricas)
```

### Dataset de Entrenamiento

- **Fuente**: CICIoT2023 (Canadian Institute for Cybersecurity)
- **Tama√±o**: Subset preprocesado
- **Distribuci√≥n**: Desbalanceada (refleja tr√°fico real)
- **Features**: 16 componentes PCA (reducci√≥n de features originales)
- **Preprocesamiento**:
  - Normalizaci√≥n con StandardScaler
  - Reducci√≥n dimensional PCA
  - Manejo de valores faltantes

### Diferencias con Modelo Sint√©tico

| Aspecto | Sint√©tico | Real |
|---------|-----------|------|
| **Accuracy** | 97.00% | 84.48% |
| **Datos** | Balanceados, sint√©ticos | Desbalanceados, reales |
| **Ruido** | Bajo | Alto (tr√°fico real) |
| **Complejidad** | Patrones claros | Patrones sutiles |
| **Generalizaci√≥n** | Excelente en datos similares | Mejor en escenarios reales |

### An√°lisis de la Brecha de Rendimiento

La diferencia de ~12-13% en accuracy se explica por:

1. **Complejidad de datos reales**: Mayor variabilidad y ruido en tr√°fico real
2. **Desbalanceo de clases**: CICIoT2023 tiene distribuci√≥n no uniforme
3. **Caracter√≠sticas sutiles**: Algunos ataques reales son m√°s dif√≠ciles de distinguir del tr√°fico normal
4. **Tama√±o del dataset**: Potencialmente menor cantidad de ejemplos de entrenamiento

**Sin embargo**: 84.48% sigue siendo un desempe√±o s√≥lido y competitivo para detecci√≥n de amenazas IoT en entornos reales.

---

## Especificaciones de Entrenamiento

### Hiperpar√°metros Comunes

| Par√°metro | Valor |
|-----------|-------|
| **Optimizer** | Adam |
| **Learning Rate** | 0.001 |
| **Batch Size** | 64 |
| **Epochs** | 100 (con Early Stopping) |
| **Early Stopping Patience** | 10 epochs |
| **Early Stopping Monitor** | val_loss |
| **Validation Split** | 20% |

### Arquitectura de Red

| Capa | Par√°metros |
|------|------------|
| **Input** | 16 neurons |
| **Encoder Hidden** | 8 neurons, ReLU |
| **Latent Space** | 4 neurons, ReLU |
| **Decoder Hidden** | 8 neurons, ReLU |
| **Decoder Output** | 16 neurons, Linear |
| **Classifier Hidden** | 16 neurons, ReLU, Dropout(0.3) |
| **Classifier Output** | 8 neurons, Softmax |

### Regularizaci√≥n

- **Dropout**: 0.3 en capa oculta del clasificador
- **L2 Regularization**: No aplicada
- **Batch Normalization**: No aplicada
- **Early Stopping**: S√≠, patience=10

---

## Preprocesamiento de Datos

### Reducci√≥n Dimensional con PCA

**Objetivo**: Reducir dimensionalidad de 35 features a 16 componentes principales.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=16)
X_pca = pca.fit_transform(X_original)

# Varianza explicada: ~95%
```

**Justificaci√≥n**:
- Reduce complejidad computacional
- Elimina features redundantes
- Mantiene 95% de varianza explicada
- Mejora generalizaci√≥n del modelo

### Normalizaci√≥n con StandardScaler

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_pca)

# Asegura media=0, std=1 para cada feature
```

**Justificaci√≥n**:
- Mejora convergencia del entrenamiento
- Evita dominancia de features con mayor escala
- Requisito para PCA efectivo

### Codificaci√≥n de Etiquetas

```python
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_labels)

# Convierte etiquetas textuales a n√∫meros 0-7
```

---

## Formato de Entrada Esperado

### Para Inferencia

El modelo espera un array NumPy con las siguientes caracter√≠sticas:

```python
# Forma esperada
sample.shape = (16,)  # Vector de 16 componentes

# Ejemplo de muestra
sample = np.array([
    0.23, -1.45, 0.89, -0.12,  # PC1-PC4
    1.34, -0.67, 0.45, -1.23,  # PC5-PC8
    0.56, -0.89, 1.12, -0.34,  # PC9-PC12
    0.78, -1.01, 0.23, -0.56   # PC13-PC16
])

# IMPORTANTE: La muestra debe estar normalizada con el StandardScaler
sample_scaled = scaler.transform(sample.reshape(1, -1))
```

### Para Batch Processing

```python
# Forma esperada
X_batch.shape = (n_samples, 16)

# Ejemplo
X_batch = np.array([
    [0.23, -1.45, ..., -0.56],  # Muestra 1
    [1.12, -0.34, ..., 0.78],   # Muestra 2
    ...
])

# Normalizar batch completo
X_batch_scaled = scaler.transform(X_batch)
```

---

## Carga y Uso de Modelos

### Cargar Modelo Sint√©tico

```python
import tensorflow as tf
import pickle
import numpy as np

# Cargar modelo Keras
model = tf.keras.models.load_model('models/modelo_ae_fnn_iot_synthetic.h5')

# Cargar componentes de preprocesamiento
with open('models/scaler_synthetic.pkl', 'rb') as f:
    scaler = pickle.load(f)

with open('models/label_encoder_synthetic.pkl', 'rb') as f:
    label_encoder = pickle.load(f)

# Cargar nombres de clases
class_names = np.load('models/class_names_synthetic.npy')
```

### Realizar Predicci√≥n

```python
def predict_threat(sample):
    """
    Predice la clase de una muestra de tr√°fico

    Args:
        sample: Array de 16 componentes PCA (sin normalizar)

    Returns:
        prediction: Nombre de la clase predicha
        probabilities: Array con probabilidades de cada clase
        confidence: Confianza de la predicci√≥n (%)
    """
    # Normalizar muestra
    sample_scaled = scaler.transform(sample.reshape(1, -1))

    # Predecir
    predictions = model.predict(sample_scaled, verbose=0)

    # El modelo tiene 2 outputs: reconstrucci√≥n y clasificaci√≥n
    # Usar solo la salida de clasificaci√≥n
    class_probabilities = predictions[1] if isinstance(predictions, list) else predictions

    # Obtener clase predicha
    predicted_class_idx = np.argmax(class_probabilities[0])
    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]

    # Calcular confianza
    confidence = np.max(class_probabilities[0]) * 100

    return predicted_class, class_probabilities[0], confidence
```

### Ejemplo de Uso

```python
# Muestra de ejemplo (16 componentes PCA)
sample = np.array([
    0.23, -1.45, 0.89, -0.12,
    1.34, -0.67, 0.45, -1.23,
    0.56, -0.89, 1.12, -0.34,
    0.78, -1.01, 0.23, -0.56
])

# Predecir
prediction, probabilities, confidence = predict_threat(sample)

print(f"Predicci√≥n: {prediction}")
print(f"Confianza: {confidence:.2f}%")
print(f"Probabilidades por clase:")
for i, class_name in enumerate(class_names):
    print(f"  {class_name}: {probabilities[i]*100:.2f}%")
```

**Salida esperada:**
```
Predicci√≥n: DDoS
Confianza: 94.23%
Probabilidades por clase:
  Benign: 1.23%
  DDoS: 94.23%
  DoS: 2.45%
  Brute_Force: 0.56%
  Spoofing: 0.78%
  MITM: 0.34%
  Scan: 0.23%
  Recon: 0.18%
```

---

## Interpretaci√≥n de Resultados

### Niveles de Confianza

- **>90%**: Alta confianza - Predicci√≥n muy confiable
- **70-90%**: Confianza moderada - Predicci√≥n confiable
- **50-70%**: Confianza baja - Requiere verificaci√≥n
- **<50%**: Muy baja confianza - Muestra ambigua

### Umbrales de Alerta

Para sistemas de producci√≥n, se recomiendan los siguientes umbrales:

| Nivel | Confianza | Acci√≥n |
|-------|-----------|--------|
| üü¢ Normal | <50% amenaza | Permitir tr√°fico |
| üü° Sospechoso | 50-80% amenaza | Monitorear, logging |
| üü† Probable Amenaza | 80-90% amenaza | Alerta, an√°lisis adicional |
| üî¥ Amenaza Confirmada | >90% amenaza | Bloquear, escalar |

---

## Limitaciones Conocidas

### Modelo Sint√©tico

1. **Clase MITM**: Recall de solo 68%, muchos falsos negativos
2. **Generalizaci√≥n**: Optimizado para datos sint√©ticos, puede tener menor rendimiento con datos reales
3. **Nuevos Ataques**: No detecta tipos de ataques no presentes en entrenamiento

### Modelo Real

1. **Accuracy Moderada**: 84.48% es bueno pero no excepcional
2. **Desbalanceo**: Rendimiento var√≠a significativamente entre clases
3. **Datos de Entrenamiento**: Limitado por el tama√±o del dataset CICIoT2023 disponible

### Ambos Modelos

1. **Dependencia de PCA**: Requiere transformaci√≥n PCA espec√≠fica de los datos originales
2. **Drift de Datos**: Rendimiento puede degradarse con nuevos patrones de tr√°fico
3. **Explicabilidad**: Como deep learning, las decisiones no son f√°cilmente interpretables
4. **Latent Space Fijo**: 4 dimensiones pueden no capturar toda la complejidad

---

## Recomendaciones de Mejora Futura

### Corto Plazo

1. **Mejorar detecci√≥n de MITM**: Recolectar m√°s ejemplos, aplicar t√©cnicas de balanceo
2. **Ensemble Methods**: Combinar predicciones de ambos modelos
3. **Ajuste de Hiperpar√°metros**: Grid search para Œª‚ÇÅ, Œª‚ÇÇ, learning rate
4. **Data Augmentation**: Generar variaciones de muestras de entrenamiento

### Largo Plazo

1. **Arquitecturas Avanzadas**: Explorar Transformers, GNNs para datos de red
2. **Transfer Learning**: Pre-entrenar en datasets grandes, fine-tune en CICIoT2023
3. **Detecci√≥n de Anomal√≠as**: Usar error de reconstrucci√≥n para detectar ataques desconocidos
4. **Reentrenamiento Continuo**: Actualizar modelo con nuevos datos peri√≥dicamente
5. **Explicabilidad**: Implementar SHAP, LIME para interpretar decisiones

---

## Referencias T√©cnicas

### Papers

- Canadian Institute for Cybersecurity. (2023). CICIoT2023 Dataset
- Autoencoder-Based Deep Learning for Network Intrusion Detection
- Multi-task Learning for Cybersecurity Applications

### Frameworks

- TensorFlow 2.10+
- Keras 2.10+
- scikit-learn 1.2+
- NumPy 1.23+

---

**√öltima actualizaci√≥n**: Noviembre 2024
